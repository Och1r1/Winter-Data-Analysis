{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f817d3ea-32fb-4850-849b-8ffa56970335",
   "metadata": {},
   "source": [
    "## Winter Analysis Data Challenge :OO\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b59e1ea-2458-4fc9-8c70-c03e576dd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import text, create_engine\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import time\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560793cc-bb49-489e-b31f-58fff66bb25c",
   "metadata": {},
   "source": [
    "### Setting up Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ba69c0-12f4-4330-beea-2db31d1e5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station Entries\n",
    "stationEntries = pd.read_csv('TrainStationEntriesExits/train-station-entries-exits-data-may-2025.csv')\n",
    "# Station Entrance\n",
    "stationEntrances = pd.read_csv('TrainStationEntranceLocations/stationentrances2020_v4.csv')\n",
    "# Opal Patronage\n",
    "opal = pd.read_csv('OpalPatronage/Opal_Patronage_20200101.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad54628-a519-4a1d-91f3-472f33630613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2023 Opal files to process\n"
     ]
    }
   ],
   "source": [
    "# Process multiple Opal files\n",
    "data_folder = \"OpalPatronage\"\n",
    "file_list = [f for f in os.listdir(data_folder) if f.startswith(\"Opal_Patronage_\") and f.endswith(\".txt\")]\n",
    "\n",
    "print(f\"Found {len(file_list)} Opal files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc869b3-9933-4d2a-b323-98b70a587fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Opal dataset shape: (1372294, 6)\n"
     ]
    }
   ],
   "source": [
    "df_list = [] \n",
    "for file in file_list: \n",
    "    file_path = os.path.join(data_folder, file) \n",
    "    df = pd.read_csv(file_path, sep=\"|\") \n",
    "    df_list.append(df) \n",
    "\n",
    "# Combine all Opal data\n",
    "opal_combined = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"Combined Opal dataset shape: {opal_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57b290-4c77-43aa-b5af-5816d1d42b5d",
   "metadata": {},
   "source": [
    "### Data Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802f9d20-076e-42c4-9810-28fd426c9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Station Entries data...\n",
    "# Step 1: Convert MonthYear to a datetime period (or datetime)\n",
    "stationEntries['MonthYear'] = pd.to_datetime(stationEntries['MonthYear'], format='%b-%y', errors='coerce')\n",
    "\n",
    "# Step 2: Replace 'Less than 50' with an estimate (like 49) or NaN\n",
    "stationEntries['Trip'] = stationEntries['Trip'].replace('Less than 50', '49')\n",
    "\n",
    "# Step 3: Convert Trip to numeric\n",
    "stationEntries['Trip'] = pd.to_numeric(stationEntries['Trip'], errors='coerce')\n",
    "stationEntries.rename(columns={'MonthYear': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b13bf5-afba-408d-aaff-ca9c9bf499c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Station Entrances\n",
    "stationEntrances['Street_Type'] = stationEntrances['Street_Type'].replace('<Null>', np.nan)\n",
    "\n",
    "srid = 4283\n",
    "stationEntrances['geom'] = gpd.points_from_xy(stationEntrances.LONG, stationEntrances.LAT)  # creating the geometry column\n",
    "stationEntrances = stationEntrances.drop(columns=['LAT', 'LONG'])  # removing the old latitude/longitude fields\n",
    "stationEntrances['geom'] = stationEntrances['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b11148-1a71-47ad-bed3-09bde2f071ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned Opal dataset shape: (1327188, 6)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Opal Numeric\n",
    "def clean_opal_numeric(x): \n",
    "    \"\"\"Clean numeric fields that may contain '<50', '<100' etc.\"\"\"\n",
    "    if isinstance(x, str) and \"<\" in x: \n",
    "        return 0  # Convert to 0 for analysis\n",
    "    elif x is None: \n",
    "        return None\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def clean_mode_name(x): \n",
    "    \"\"\"Remove UNKNOWN mode entries\"\"\"\n",
    "    if x != \"UNKNOWN\": \n",
    "        return str(x)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create cleaned opal dataset\n",
    "opal_clean = opal_combined.copy()\n",
    "\n",
    "# Standardize column names to lowercase\n",
    "opal_clean.columns = opal_clean.columns.str.lower()\n",
    "\n",
    "# Clean numeric columns\n",
    "opal_clean[\"tap_ons\"] = opal_combined[\"Tap_Ons\"].apply(clean_opal_numeric)\n",
    "opal_clean[\"tap_offs\"] = opal_combined[\"Tap_Offs\"].apply(clean_opal_numeric)\n",
    "\n",
    "# Clean mode names and remove UNKNOWN entries\n",
    "opal_clean[\"mode_name\"] = opal_combined[\"mode_name\"].apply(clean_mode_name)\n",
    "opal_clean = opal_clean.dropna(subset=[\"mode_name\"])\n",
    "\n",
    "# Convert date column\n",
    "opal_clean['trip_origin_date'] = pd.to_datetime(opal_clean['trip_origin_date'])\n",
    "\n",
    "print(f\"Final cleaned Opal dataset shape: {opal_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780b983-d989-407e-acb7-fb20634175c3",
   "metadata": {},
   "source": [
    "### Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123b6097-4d11-4a9d-b347-b40d454820ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "\n",
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"winter\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        port       = db_conn_dict['port']\n",
    "        try:\n",
    "            db = create_engine(f'postgresql+psycopg2://{db_user}:{db_pw}@{host}:{port}/{default_db}', connect_args={\"options\": \"-csearch_path=assignment\"}, echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    conn.commit()\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(text(sqlcmd), args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c85066-5155-46a1-82ba-6dde229ba7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f0fb3-79cf-4983-b430-8983725b42b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9bf6e-eacd-4c1e-8f39-43808d759c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890d160-ae5a-439f-95de-55df1a612730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb583e43-db0d-457a-a254-7c241f2275e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baea1be-546e-4eaa-86a1-0c79d5c1d7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5e927-a762-422a-9f84-dd861902795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e870e58-3dca-4e2b-9f7f-83efb009cf16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61f06b-7e9f-4837-8d8e-cb7f4786dac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318a63d-64e1-42d6-924f-4a1fe5565138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad270c4-a31e-406e-948c-d2e7ea5db5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b97b5e-cb57-4119-8b8f-45cfa4c7ae44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
